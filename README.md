# __Tensorflow_Tutorial__

This tutorial covers the basics of Deep Learning with Convolutional Neural Nets. The tutorial is broken into two notebooks. The topics covered in each notebook are:

## __Introduction:__

- **Linear Regression** as __single layer, single neuron model__ to motivate the introduction of Neural Networks as Universal Approximators that are modeled as collections of neurons connected in an acyclic graph

- __Loss/Error functions__, __Gradient Decent__, __Backpropagation__, etc

- Neural Network with hands on Tensorflow Implementation

## __CNN_Mnist_CIFAR-10:__

- __Convolutions__ and examples of simple __image filters__ to motivate the construction of __Convolutionlal Neural Networks.__
- Example: CNN on Mnist
    - Visualizing Data
    - Constructing simple Convolutional Neural Networks
    - Training and Inference
    - Visualizing/Interpreting trained Neural Nets
- Example: CNN on CIFAR-10

# __References:__

The code examples presented here are mostly taken (verbatim) or inspired from the following sources. I made this curation to give a quick exposure to very basic but essential ideas/practices in deep learning to get you started fairly quickly, but I recommend going to some or all of the actual sources for an in depth survey:

- [CS231n: Convolutional Neural Networks for Visual Recognition](http://cs231n.stanford.edu/)
- [Deep Learnig Specialization, Andrew Ng](https://www.coursera.org/specializations/deep-learning?utm_source=deeplearningai&utm_medium=institutions&utm_campaign=WebsiteCoursesDLSTopButton)
- [Deep Learning with Python](https://www.amazon.com/Deep-Learning-Python-Francois-Chollet/dp/1617294438)
- [Keras Blog](https://blog.keras.io/)
- [HAL Training Series](https://ai.ncsa.illinois.edu/hal-trainings/2022-fall-training/)
- [ALCF Training Series](https://github.com/argonne-lcf/ai-science-training-series)